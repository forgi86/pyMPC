\documentclass[a4paper,12pt,fleqn]{book}
\usepackage{amsmath}
\usepackage{graphicx}


\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{subfigure}
\usepackage{amssymb}

\newcommand{\MPC}{\mathrm{MPC}}
\newcommand{\varx}{\mathbf{x}}
\newcommand{\varu}{\mathbf{u}}
\newcommand{\slack}{\epsilon}
\newcommand{\QxN}{Q_{x_N}}
\newcommand{\Qx}{Q_{x}}
\newcommand{\Qu}{Q_{u}}
\newcommand{\Qdu}{Q_{\Delta u}}
\newcommand{\Np}{{N_p}}
\newcommand{\Nc}{{N_c}}
\newcommand{\blkdiag}{\text{blkdiag}}

\begin{document}

 \title{pyMPC Documentation}
\author{Marco Forgione}

\maketitle

\chapter{Mathematical formulation}
The MPC problem solved by pyMPC is:
\begin{subequations}
\label{eq:MPC}
\begin{align}
  &\arg \min_{\varx,\varu} 
  \overbrace{\big(x_N - x_{ref}\big)^\top \QxN \big(x_N - x_{ref}\big)}^{=J_{x_N}} + 
  \overbrace{\sum_{k=0}^{\Np-1} \big(x_k - x_{ref}\big)^\top \Qx\big(x_k - x_{ref}\big)}^{J_{x}}+ \nonumber \\
  &  + 
    \overbrace{\sum_{k=0}^{\Np-1} \big(u_k - u_{ref}\big)^\top \Qu \big(u_k - u_{ref}\big)}^{J_u}
    +  
  \overbrace{\sum_{k=0}^{\Np-1} \Delta u_k^\top \Qdu \Delta u_k}^{J_{\Delta u}} \\ \nonumber
  &\text{subject to} \nonumber\\
  &x_{k+1} = Ax_k + B u_k \label{eq:linear_dynamics} \\ 
  &u_{min} \leq u_k \leq u_{max}\\
  &x_{min} \leq x_k \leq x_{max}\\
  &\Delta u_{min} \leq \Delta u_k \leq \Delta u_{max}\\
  &x_0 = \bar x\\
  &u_{-1} = \bar u
\end{align}
\end{subequations} where $\Delta u_k = u_k - u_{k-1}$.

The optimization variables are 
\begin{align}
  \varx & = \begin{bmatrix}x_0 & x_1 & \dots & x_\Np\end{bmatrix},\\
  \varu & = \begin{bmatrix}u_0 & u_1 & \dots & u_{\Np-1}\end{bmatrix},\\  
\end{align}
In a typical implementation, the MPC input is applied in \emph{receding horizon}. At each time step $i$, the problem \eqref{eq:MPC} is solved with $x_0=x[i],\;u_{-1}=u[{i-1}]$ and an optimal input sequence $u_{0},\dots,u_{\Np}$ is obtained. The first element of this sequence $u_0$ is the control input that is actually applied at time instant $i$. At time instant $i+1$, a new state $x[i+1]$ is measured (or estimated), and the process is iterated. 

Thus, formally, the MPC control law is a (static) function of the current state and the previous input:
\begin{equation}
 u_{MPC} = K(x[i], u[i-1]).
\end{equation}

Note that this function also depends on the references $x_{ref}$ and $u_{ref}$ and on the system matrices $A$ and $B$.

\section{Quadratic Programming Formulation}
The QP solver expects a problem with form: 
\begin{subequations}
\label{eq:QP}
\begin{align}
 &\min \frac{1}{2} x^\top P x +  q^\top x \\
 &\text{subject to} \nonumber \\
 &l \leq Ax \leq u
\end{align}
\end{subequations}
The challenge here is to rewrite the MPC optimization problem \eqref{eq:MPC} in form
\eqref{eq:QP} to use the standard QP solver. 

\subsection{Cost function}
By direct inspection, the non-constant terms of the cost function in $Q_x$ are:
\begin{multline}
\label{eq:J_Qx}
 J_{Q_x} = \frac{1}{2}
 \begin{bmatrix}
  x_0^\top & x_1^\top &\dots & x_{\Np-1}^\top
 \end{bmatrix}^\top
 \blkdiag(Q_x, Q_x, \dots, Q_x)
 \begin{bmatrix}
  x_0 \\  x_1\\ \vdots\\  x_{\Np-1}
 \end{bmatrix}
 %\begin{bmatrix}
 % Q_x       & 0  &\dots   & \dots & 0\\
 % 0         & Q_x  &0       & \dots & 0\\
 % 0         & 0     &\ddots  & \dots & 0\\
 % \vdots         & 0    &0       & Q_x & 0\\ 
 % 0         & 0    &0       & 0 &  Q_x\ 
 % \end{bmatrix}
 + \\
 +
  \begin{bmatrix}
  -x_{ref}^\top Q_x & -x_{ref}^\top Q_x &\dots & -x_{ref}^\top Q_x
 \end{bmatrix} 
 \begin{bmatrix}
  x_0 \\ x_1 \\ \vdots \\ x_{\Np-1}
 \end{bmatrix}^\top 
 \end{multline}
 and similarly for the term $J_{Q_{x_\Np}}$ and $J_{Q_u}$: 
\begin{multline}
\label{eq:J_Qu}
 J_{Q_u} = \frac{1}{2}
 \begin{bmatrix}
  u_0^\top & u_1^\top &\dots & u_{\Np-1}^\top
 \end{bmatrix}
 \blkdiag(Q_u, Q_u, \dots, Q_u)
 \begin{bmatrix}
  u_0 \\  u_1\\ \vdots\\  u_{\Np-1}
 \end{bmatrix}
  + \\
 +
  \begin{bmatrix}
  -u_{ref}^\top Q_u & -u_{ref}^\top Q_u &\dots & -u_{ref}^\top Q_u
 \end{bmatrix}
 \begin{bmatrix}
  u_0 \\ u_1 \\ \vdots \\ u_{\Np-1}
 \end{bmatrix} 
 \end{multline}
 For the terms in $Q_\Delta u$ we have instead
\begin{multline}
 J_{\Delta u} = \frac{1}{2}
 \begin{bmatrix}
  u_0 & u_1 &\dots & u_{\Np-1}
 \end{bmatrix}^\top
  \begin{bmatrix}
  2Q_{\Delta u} & -Q_{\Delta u} &0                  & \dots         & \dots  &   0\\
  -Q_{\Delta u} & 2Q_{\Delta u} &-Q_{\Delta u}      &0              & \dots  &   0\\
  0             & -Q_{\Delta u} &\ddots             & \ddots        &\ddots  &   0\\
  0             & 0             &\ddots             & \ddots        &\ddots  &   0\\  
  0             & 0             &\ddots             & \ddots        &\ddots  &   0\\
  0             & 0             &0                  &-Q_{\Delta u}  & 2Q_{\Delta u} &-Q_{\Delta u}\\  
  0             & 0             &0                  &0              & -Q_{\Delta u} &Q_{\Delta u}\\  
  \end{bmatrix}
 \begin{bmatrix}
  u_0 \\  u_1\\ \vdots\\  u_{\Np-1}
 \end{bmatrix}^\top
 + \\
 +
  \begin{bmatrix}
  -{\bar u}^\top Q_{\Delta u} & 0 & \dots  & 0
 \end{bmatrix}
 \begin{bmatrix}
  u_0 \\ u_1 \\ \vdots \\ u_{\Np-1}
 \end{bmatrix}^\top 
 \end{multline} 
\subsection{Constraints}
\subsubsection{Linear dynamics}
Let us consider the linear equality constraints \eqref{eq:linear_dynamics} representing the system dynamics. These can 
be written in matrix form as
\begin{equation}
\begin{bmatrix}
x_0\\
x_1\\
\vdots\\
x_{\Np-1}\\
x_{\Np}
\end{bmatrix}=
\overbrace{
\begin{bmatrix}
 0      &0      &\dots  &0\\
 A_d    &0      &\dots  & 0\\
 0      &A_d    &\dots  &0\\
 \vdots &0      &\ddots & 0\\
 0      &0      &\dots  &A_d
\end{bmatrix}
}^{=\mathcal{A}}
\begin{bmatrix}
x_0\\
x_1\\
\vdots\\
x_{\Np-1}\\
x_{\Np} 
\end{bmatrix} +
\overbrace{
\begin{bmatrix}
 0      &0      &\dots  &0\\
 B_d    &0      &\dots  & 0\\
 0      &B_d    &\dots  &0\\
 \vdots &0      &\ddots & 0\\
 0      &0      &\dots  &B_d
\end{bmatrix}
}^{=\mathcal B}
\begin{bmatrix}
u_0\\
u_1\\
\vdots\\
u_{\Np-2}\\
u_{\Np-1} 
\end{bmatrix} +
\overbrace{
\begin{bmatrix}
\bar x\\
0\\
\vdots\\
\vdots \\
0 
\end{bmatrix}
}^{=\mathcal{C}}
\end{equation}
we get a set of linear equality constraints representing the system dynamics \eqref{eq:linear_dynamics}.
These constraints can be written as
\begin{equation}
 \begin{bmatrix}
  (\mathcal{A}-I) & \mathcal{B}
 \end{bmatrix}
 \begin{bmatrix}
  x\\
  u
 \end{bmatrix}
 = \mathcal{C}.
\end{equation}
\subsubsection{Variable bounds: $x$ and $u$}
Bounds on $x$ and $u$ are readily implemented as
\begin{equation}
\begin{bmatrix}
 x_{min}\\u_{min}
\end{bmatrix}
\leq
\begin{bmatrix}
 I &0\\
 0 & I
\end{bmatrix}
\begin{bmatrix}
 x\\u
\end{bmatrix}
\leq
\begin{bmatrix}
 x_{max}\\u_{max}
\end{bmatrix}.
\end{equation}
\subsubsection{Variable bounds: $\Delta u$}
\begin{equation}
\begin{bmatrix}
u_{-1} +\Delta u_{min}\\
\Delta u_{min}\\
\vdots\\
\Delta u_{min}\\
\end{bmatrix} \leq 
\begin{bmatrix}
  I  &  0 & \dots & \dots  & 0 & 0\\
 -I  &  I &  0    & \dots  & 0 & 0\\
  0  & -I &  I    & \dots  & 0 & 0\\
	\vdots\\
	0  &  0 & \dots & 0      &-I & I\\    
\end{bmatrix}
\begin{bmatrix}
u_0\\
u_1\\
\vdots\\
u_{\Nc-1}\\
\end{bmatrix}
\leq 
\begin{bmatrix}
u_{-1} +\Delta u_{max}\\
\Delta u_{max}\\
\vdots\\
\Delta u_{max}\\
\end{bmatrix}
\end{equation}

\subsubsection{Slack variables}
Bounds on $x$ may result in an problem unfeasible! A common solution
is to transform the hard constraints in $x$ into soft constraints by means of  \emph{slack variables} $\slack$.
\begin{equation}
\begin{bmatrix}
 x_{min}\\u_{min}
\end{bmatrix}
\leq
\begin{bmatrix}
 I &0 &I\\
 0 &I & 0
\end{bmatrix}
\begin{bmatrix}
 x\\
 u\\
 \slack
\end{bmatrix}
\leq
\begin{bmatrix}
 x_{max}\\u_{max}
\end{bmatrix}
\end{equation}.

\section{Control Horizon}
Sometimes, we may want to use a control horizon $\Nc < \Np$ instead of the standard $\Nc = \Np$. The input is constant for $\Nc \geq \ Np$.

\begin{equation}
\begin{bmatrix}
x_0\\
x_1\\
\vdots\\
x_{\Np-1}\\
x_{\Np}
\end{bmatrix}=
\overbrace{
\begin{bmatrix}
 0      &0      &\dots  &0\\
 A_d    &0      &\dots  & 0\\
 0      &A_d    &\dots  &0\\
 \vdots &0      &\ddots & 0\\
 0      &0      &\dots  &A_d
\end{bmatrix}
}^{=\mathcal{A}}
\begin{bmatrix}
x_0\\
x_1\\
\vdots\\
x_{\Np-1}\\
x_{\Np} 
\end{bmatrix} +
\overbrace{
\begin{bmatrix}
 0      &0      &\dots  &0\\
 B_d    &0      &\dots  & 0\\
 0      &B_d    &\dots  &0\\
 \vdots &0      &\ddots & 0\\
 0      &0      &\dots  &B_d\\
 0      &0      &\dots  &\vdots\\
 0      &0      &\dots  &B_d\\
\end{bmatrix}
}^{=\mathcal B}
\begin{bmatrix}
u_0\\
u_1\\
u_2\\
\vdots\\
u_{\Nc-1}\\
\vdots\\
u_{\Nc-1}
\end{bmatrix} +
\overbrace{
\begin{bmatrix}
\bar x\\
0\\
\vdots\\
\vdots \\
0 
\end{bmatrix}
}^{=\mathcal{C}}
\end{equation}

The contributions $J_{Q_u}$ of the cost function also changes:
\begin{multline}
\label{eq:J_Qu_Nc}
 J_{Q_u} = \frac{1}{2}
 \begin{bmatrix}
  u_0^\top & u_1^\top &\dots & u_{\Np-1}^\top
 \end{bmatrix}
 \blkdiag\bigg(Q_u, Q_u, \dots, (\Np - \Nc + 1)Q_u\bigg)
 \begin{bmatrix}
  u_0 \\  u_1\\ \vdots\\  u_{\Np-1}
 \end{bmatrix}
  + \\
 +
  \begin{bmatrix}
  -u_{ref}^\top Q_u & -u_{ref}^\top Q_u &\dots & -(\Np - \Nc + 1)u_{ref}^\top Q_u
 \end{bmatrix}
 \begin{bmatrix}
  u_0 \\ u_1 \\ \vdots \\ u_{\Np-1}
 \end{bmatrix}
 \end{multline}
Instead, $J_\Delta u$ does not change (because the input is constant for $k \geq N_c$!


\chapter{Alternative Implementation}

\begin{equation}
\begin{bmatrix}
x_1\\
x_2\\
\vdots\\
x_{\Np-1}\\
x_{\Np}
\end{bmatrix}=
\overbrace{
\begin{bmatrix}
A_d\\
A_d^2\\
\vdots\\
A_d^{\Np-1}\\
A_d^\Np
\end{bmatrix}
}^{=\mathcal{A}}
x_0 + 
\overbrace{
\begin{bmatrix}
 B_d                &0              &0              &\dots      &0      &0\\
 AB_d               &B_d            &0              &\dots      &0      &0\\
 \dots              &\dots          &\dots          &\dots     &0       &0\\
 A^{\Np-2}B_d       &A^{\Np-3}B_d   &A^{\Np-4}B_d   &\dots     &B       &0\\
 A^{\Np-1}B_d       &A^{\Np-2}B_d   &A^{\Np-3}B_d   &\dots     &AB      &A \\
\end{bmatrix}
}^{=\mathcal B}
\begin{bmatrix}
u_0\\
u_1\\
u_2\\
\vdots\\
u_{\Np-1}
\end{bmatrix}
\end{equation}

\begin{equation}
 J_{Q_x} = \frac{1}{2} \left(\mathcal{A} x_0 + \mathcal{B} U - X_{ref}\right)^\top \mathcal{Q}_x \left(\mathcal{A} x_0 + \mathcal{B} U - X_{ref}\right)
\end{equation}

\begin{equation}
 J_{Q_u} =  \frac{1}{2} (U - U_{ref})^\top \mathcal{Q}_u (U-U_{ref})
\end{equation}

\begin{equation}
 J_{Q_{\Delta u}} =  \frac{1}{2} U^\top \mathcal{Q}_{\Delta u} U +   
 \begin{bmatrix}
  -{\bar u}^\top Q_{\Delta u} & 0 & \dots  & 0
 \end{bmatrix} U
\end{equation}

Summing up and expanding terms:
\begin{multline}
 J = 
 \frac{1}{2}U^\top \mathcal{B}^\top \mathcal{Q}_x \mathcal{B} U + 
 \frac{1}{2} (\mathcal{A}x_o - X_{ref})^\top \mathcal{Q}_x (\mathcal{A}x_0-X_{ref}) +
 (\mathcal{A}x_0 -X_{ref})^\top\mathcal{Q}_x \mathcal{B} U + \\
 + \frac{1}{2} U^\top \mathcal{Q}_u U +
 \frac{1}{2}U_{ref}^\top \mathcal{Q}_uU^{ref} + 
 -U_{ref}^\top\mathcal{Q}_u U +\\ 
 +\frac{1}{2} U^\top \mathcal{Q}_{\Delta u} U +
\begin{bmatrix}
  -{\bar u}^\top Q_{\Delta u} & 0 & \dots  & 0
 \end{bmatrix} U 
\end{multline}
Neglecting constant terms and collecting:
\begin{multline}
 J = C + \frac{1}{2} U^\top \overbrace{\big(\mathcal{B}^\top \mathcal{Q}_x \mathcal{B}\big)} ^{=\mathcal{P}}U + \\
 \overbrace{\bigg [(\mathcal{A}x_o - X_{ref})^\top \mathcal{Q}_x \mathcal{B} -U_{ref}^\top\mathcal{Q}_u -
 \begin{bmatrix}
  {\bar u}^\top Q_{\Delta u} & 0 & \dots  & 0
 \end{bmatrix}\bigg)}^{=b^\top} U
\end{multline}
Thus, be have
\begin{equation}
 b = \mathcal{B}^\top \mathcal{Q}_x(\mathcal{A}x_0 - X_{ref}) - \mathcal{Q}_uU_{ref} - 
  \begin{bmatrix}
 -Q_{\Delta u} \bar{u} \\ 0 \\ \vdots \\0
 \end{bmatrix}
\end{equation}

For the unconstrained problem the minimum is in 
\begin{equation}
 U^{opt} = -P^{-1}b
\end{equation}
\end{document} 

